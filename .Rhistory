ylab = "full-stimulus set"
)
lvl <- level[1]
df <- cortrials
df <- droplevels(subset(df, focus==substr(lvl, 1, 1) &
featg!="noise" & featl!="patch"))
df <- outgoners(df, df$t_reaction)
bkxrt <- with(df, tapply(t_reaction, block, mean))
stxbkrt <- ddply(df, .(set, block), summarize, rt=mean(t_reaction))
stxbkrt$bpset <- seq(1, 12)
sxbmat <- stxbkrt[,c(1,3,4)]
sxbmat1 <- reshape(sxbmat, idvar="set", timevar="bpset", direction="wide")
sxbmat2 <- data.matrix(sxbmat1[,2:13])
rownames(sxbmat2) <- sxbmat1$set
# following code limits the lowest and highest color to 5%, and 95% of range
# quantile.range <- quantile(sxbmat2, probs = seq(0, 1, 0.01))
# palette.breaks <- seq(quantile.range["1%"], quantile.range["99%"], 0.1)
heatmap.2(
sxbmat2,
Rowv=NA, Colv=NA,
dendrogram = "none",
scale = "none",
trace = "none",
col = bwrcol,
#key and key labels
#   key        = FALSE,
keysize = 3,
key.title = "",
density.info=c("density"),
denscol="black",
key.xlab = "RT (sec)",
key.ylab = "",
key.ytick = "",
#row, column labels
#   labRow     = NA,
labCol = 1:12,
srtCol = 0,
#plot labels
main = paste0(lvl, "\n RT/block"),
xlab = "block / set",
ylab = "full-stimulus set"
)
library(plyr)
df <- cortrials
df <- droplevels(subset(df, focus==substr(lvl, 1, 1) &
featg!="noise" & featl!="patch"))
df <- outgoners(df, df$t_reaction)
bkxrt <- with(df, tapply(t_reaction, block, mean))
stxbkrt <- ddply(df, .(set, block), summarize, rt=mean(t_reaction))
stxbkrt$bpset <- seq(1, 12)
sxbmat <- stxbkrt[,c(1,3,4)]
sxbmat1 <- reshape(sxbmat, idvar="set", timevar="bpset", direction="wide")
sxbmat2 <- data.matrix(sxbmat1[,2:13])
rownames(sxbmat2) <- sxbmat1$set
# following code limits the lowest and highest color to 5%, and 95% of range
# quantile.range <- quantile(sxbmat2, probs = seq(0, 1, 0.01))
# palette.breaks <- seq(quantile.range["1%"], quantile.range["99%"], 0.1)
heatmap.2(
sxbmat2,
Rowv=NA, Colv=NA,
dendrogram = "none",
scale = "none",
trace = "none",
col = bwrcol,
#key and key labels
#   key        = FALSE,
keysize = 3,
key.title = "",
density.info=c("density"),
denscol="black",
key.xlab = "RT (sec)",
key.ylab = "",
key.ytick = "",
#row, column labels
#   labRow     = NA,
labCol = 1:12,
srtCol = 0,
#plot labels
main = paste0(lvl, "\n RT/block"),
xlab = "block / set",
ylab = "full-stimulus set"
)
help(var)
help(sd)
hydat<-droplevels(subset(tmpbk, featg!="noise" & featl!="patch"))     # 3
hydat <- outgoners(hydat, hydat$rfrtv, 1.96)
hydat <- hydat[hydat$omerr!=0 & hydat$omerr<8,]
gee_search_i <- geeglm(rfrtv ~ 1 + block + srt + omerr,
data=hydat[!is.nan(hydat$srt),],
id=ID, family=Gamma, corstr="exchangeable" )
summary(model <- gee_search_i)
#...for the local focus
gee_search_L <- geeglm(rfrtv ~ 1 + block + srt + omerr,
data=hydat[!is.nan(hydat$srt) & hydat$focus=="L",],
id=ID, family=Gamma, corstr="exchangeable" )
summary(model <- gee_search_L)
#...for the global focus
gee_search_G <- geeglm(rfrtv ~ 1 + block + srt + omerr,
data=hydat[!is.nan(hydat$srt) & hydat$focus=="G",],
id=ID, family=Gamma, corstr="exchangeable" )
summary(model <- gee_search_G)
gee_search_i <- geeglm(rfrtv ~ 1 + block + omerr, data=hydat,
id=ID, family=Gamma, corstr="exchangeable" )
summary(model <- gee_search_i)
se <- coef(summary(gee_search_i))["omerr", "Std.err"]
ci <- exp(coef(gee_search_i)["omerr"] + c(-1, 1) * se * qnorm(0.975))
cf <- exp(coef(gee_search_i)["omerr"])
qic(model)
ormnrt <- with(hydat, tapply(rfrtv, omerr, mean))
bCI <- ddply(hydat, .(omerr), bootin, varname="rfrtv")
xidx <- sort(unique(hydat$omerr))
with(hydat, plot(range(omerr), range(c(bCI$V4, bCI$V5)), type="n", xaxt="n",
xlab="",
ylab="'rule found' mean RT (sec)"))
axis(1, at=c(1:9))
polygon(c(xidx, rev(xidx)), c(bCI$V5, rev(bCI$V4)), col=5, border=NA)
with(hydat, lines(xidx, ormnrt, type="l", lwd=2, col=3))
with(bCI, lines(xidx, V4, type="l", lwd=1, col=2))
with(bCI, lines(xidx, V5, type="l", lwd=1, col=2))
ormnrtv <- ormnrt
bCIv <- bCI
hydat<-droplevels(subset(tmpbk, featg!="noise" & featl!="patch"))     # 3
hydat <- outgoners(hydat, hydat$rfrt, 1.96)
hydat <- hydat[hydat$omerr!=0 & hydat$omerr<8,]
ormnrt <- with(hydat, tapply(rfrt, omerr, mean))
bCI <- ddply(hydat, .(omerr), bootin, varname="rfrt")
# Plot RT vs RTV together
with(hydat, plot(range(omerr), range(c(bCI$V5, bCIv$V4)), type="n", xaxt="n",
xlab="'search phase' error count",
ylab="'rule found' mean RT and RTV (sec)"))
axis(1, at=c(1:9))
polygon(c(xidx, rev(xidx)), c(bCI$V5, rev(bCIv$V4)), col=5, border=NA)
with(hydat, lines(xidx, ormnrt, type="l", lwd=2, col=1))
with(hydat, lines(xidx, ormnrtv, type="l", lwd=2, col='black', lty=2))
with(bCI, lines(xidx, V4, type="l", lwd=1, col=1))
with(bCI, lines(xidx, V5, type="l", lwd=1, col=1))
with(bCIv, lines(xidx, V4, type="l", lwd=1, col='black', lty=2))
with(bCIv, lines(xidx, V5, type="l", lwd=1, col='black', lty=2))
legend("topleft", inset=c(0.05,0.05), y.intersp=1.5, cex=1, bty="n",
legend=c("RT", "RTV"), lty=c(1,2), lwd=3, col=c(1,'black'))
bwrc <- palette(c('#F0AA00','#00A0BE','#003C78','#828282','#F0F0F0','#B4BE00','#FA4100'))
with(hydat, plot(range(omerr), range(c(bCI$V5, bCIv$V4)), type="n", xaxt="n",
xlab="'search phase' error count",
ylab="'rule found' mean RT and RTV (sec)"))
axis(1, at=c(1:9))
polygon(c(xidx, rev(xidx)), c(bCI$V5, rev(bCI$V4)), col=5, border=NA)
with(hydat, lines(xidx, ormnrt, type="l", lwd=2, col=1))
with(hydat, lines(xidx, ormnrtv, type="l", lwd=2, col='black', lty=2))
with(bCI, lines(xidx, V4, type="l", lwd=1, col=1))
with(bCI, lines(xidx, V5, type="l", lwd=1, col=1))
with(bCIv, lines(xidx, V4, type="l", lwd=1, col='black', lty=2))
with(bCIv, lines(xidx, V5, type="l", lwd=1, col='black', lty=2))
legend("topleft", inset=c(0.05,0.05), y.intersp=1.5, cex=1, bty="n",
legend=c("RT", "RTV"), lty=c(1,2), lwd=3, col=c(1,'black'))
with(hydat, plot(range(omerr), range(c(bCI$V5, bCIv$V4)), type="n", xaxt="n",
xlab="",
ylab="'rule found' mean RT and RTV (sec)"))
axis(1, at=c(1:9))
polygon(c(xidx, rev(xidx)), c(bCI$V5, rev(bCI$V4)), col=5, border=NA)
with(hydat, lines(xidx, ormnrt, type="l", lwd=2, col=1))
with(hydat, lines(xidx, ormnrtv, type="l", lwd=2, col='black', lty=2))
with(bCI, lines(xidx, V4, type="l", lwd=1, col=1))
with(bCI, lines(xidx, V5, type="l", lwd=1, col=1))
with(bCIv, lines(xidx, V4, type="l", lwd=1, col='black', lty=2))
with(bCIv, lines(xidx, V5, type="l", lwd=1, col='black', lty=2))
legend("topleft", inset=c(0.05,0.05), y.intersp=1.5, cex=1, bty="n",
legend=c("RT", "RTV"), lty=c(1,2), lwd=3, col=c(1,'black'))
bCIV$V5
bCIv$V5
bCI$V5
Gormnrt <- with(hydat[hydat$focus=="G",], tapply(rfrt, omerr, mean))
Lormnrt <- with(hydat[hydat$focus=="L",], tapply(rfrt, omerr, mean))
bCIg <- ddply(hydat[hydat$focus=="G",], .(omerr), bootin, varname="rfrt")
bCIl <- ddply(hydat[hydat$focus=="L",], .(omerr), bootin, varname="rfrt")
with(hydat, plot(range(omerr), range(c(bCIl$V5, bCIg$V4)), type="n", xaxt="n",
xlab="'search phase' error count",
ylab="'rule found' mean RT (sec)"))
axis(1, at=c(1:9))
polygon(c(xidx, rev(xidx)), c(bCIg$V5, rev(bCIg$V4)), col=5, border=NA)
with(hydat, lines(xidx, Gormnrt, type="l", lwd=2, col=1))
with(hydat, lines(xidx, Lormnrt, type="l", lwd=2, col='black', lty=2))
with(bCIg, lines(xidx, V4, type="l", lwd=1, col=1))
with(bCIg, lines(xidx, V5, type="l", lwd=1, col=1))
with(bCIl, lines(xidx, V4, type="l", lwd=1, col='black', lty=2))
with(bCIl, lines(xidx, V5, type="l", lwd=1, col='black', lty=2))
legend("topleft", inset=c(0.05,0.05), y.intersp=1.5, cex=1, bty="n",
legend=c("global RT", "local RT"), lty=c(1,2), lwd=3, col=c(1,'black'))
help(p.adjust)
p <- c(0
0
0
2.00E-016
2.00E-016
2.00E-016
0.00000006
0.00005
0.006
0.07
0.07
0.12
0.14
0.2
0.3
0.3
0.4
0.4
0.5
0.6
0.8
0.9
)
p <- c(0, 0, 0, 2.00E-016, 2.00E-016, 2.00E-016, 0.00000006, 0.00005, 0.006, 0.07, 0.07, 0.12, 0.14, 0.2, 0.3, 0.3, 0.4, 0.4, 0.5, 0.6, 0.8, 0.9)
p.adj <- p.adjust(p, "holm")
p.adj
options(scipen=999)
p.adj
exit
q()
help(bootin)
library(boot)
help(bootin)
help(boot)
ic <- c(4 5 6 7 10 30
12 5 8 10 13 19 21 22 29 11 14 22
2 2 7 14 25 20 21 24 26
8 8 9 13 29 7
4 7 8 10 11 12 17 4 7 14
11 5 17 22 26 27 28 2 8 10 23
2 10 24 6 13 16 19 27
1 3 8 25 5 18
1 29 22
3 3 13 1 2 9
13 17 18
1 7 14 15 16 17 20 22 24 29 3 18
2 8 17 29 12
3 9
2 11 28 31 3 25 1 2 10 17 25
7 9 6 11 1 4 19
9 6 9 19 25 10
2 5 9 11 19 22 26
2 7 8 9 15 1 2 13 15 20 26
1 3 7 22 26 29 30 31 15
11 3 4 5 17 20 22 3 6 11 17
8 8 15 17 21 23 4 5 7
3 31 1 3 6 19 21
5 10 14 12
3 6 22 23 9
1 1 2 6 8 1 8 11 20
8 19 20 1 3 12 20 23 25
8 13 7 11 21 13 16 19
6 8 12 25 30 21
4 6 31 9 10 27
3 4 8 10 30 3
)
ic <- dataframe(4 5 6 7 10 30 NaN
12 5 8 10 13 19 21 22 29 11 14 22
2 2 7 14 25 20 21 24 26
8 8 9 13 29 7
4 7 8 10 11 12 17 4 7 14
11 5 17 22 26 27 28 2 8 10 23
2 10 24 6 13 16 19 27
1 3 8 25 5 18
1 29 22
3 3 13 1 2 9
13 17 18
1 7 14 15 16 17 20 22 24 29 3 18
2 8 17 29 12
3 NaN 9
2 11 28 31 3 25 1 2 10 17 25
7 9 6 11 1 4 19
9 6 9 19 25 10
2 5 9 11 19 22 26
2 7 8 9 15 1 2 13 15 20 26
1 3 7 22 26 29 30 31 15
11 3 4 5 17 20 22 3 6 11 17
8 8 15 17 21 23 4 5 7
3 31 1 3 6 19 21
5 10 14 12
3 6 22 23 9
1 1 2 6 8 1 8 11 20
8 19 20 1 3 12 20 23 25
8 13 7 11 21 13 16 19
6 8 12 25 30 21
4 6 31 9 10 27
3 4 8 10 30 3
)
exit
q()
set.seed(3000)
xseq<-seq(-4,4,.01)
dn1<-dnorm(xseq, 0,1)
par(mfrow=c(1,3), mar=c(3,4,4,2))
plot(xseq, dn1, col="darkgray",xlab="", ylab="Density", type="l",lwd=2, cex=2, main="PDF of Standard Normal", cex.axis=.8)
par
?par
set.seed(3000)
xseq<-seq(-4,4,.01)
dn1<-dnorm(xseq, 0,1)
par(mfrow=c(1,1), mar=c(3,4,4,2))
plot(xseq, dn1, col="darkgray",xlab="", ylab="Density", type="l",lwd=2, cex=2, main="PDF of Standard Normal", cex.axis=.8)
set.seed(3000)
xseq<-seq(-4,4,.01)
dn1<-dnorm(xseq, 0,1)
par(mfrow=c(1,1), mar=c(3,4,4,2))
plot(xseq, dn1, col="darkgray",xlab="", ylab="Density", type="l",lwd=4, cex=2, main="PDF of Standard Normal", cex.axis=.8)
save.image("~/.RData")
install.packages("dplyr")
.libPaths()
?install.packages
q()
load("~/Benslab/PairCodingR4P/bco_playground/similarity.RData")
str(df)
?substring
df$date <- substring(df$subject, 1, 8)
str(df)
unique(df$date)
order(unique(df$date))
order(df$date)
library(dplyr)
df %>% group_by(date)
df %>% group_by(date) %>% mutate(date, ntile)
df %>% group_by(date) %>% mutate(room = order(date))
df <- df %>% group_by(date) %>% mutate(room = order(date))
df <- df %>% mutate(room = order(date))
df <- df %>% group_by(date) %>% mutate(room = 1:5)
df$label <- group_indices(df, date)
?group_indices
str(df)
df$room <- group_indices(df, date)
df$label <- NULL
room1 <- df[df$room == 1]
df
df$room
room1 <- df[df$room == 1,]
room1 <- df[df$room == 4,]
room1 <- df[df$room == 1,]
room4 <- df[df$room == 4,]
room1$mdemand
mean(room1$mdemand)
mean(room4$mdemand)
mean(room1$tdemand)
mean(room4$tdemand)
mean(room1$performance)
mean(room4$performance)
mean(room1$effort)
mean(room4$effort)
mean(room1$frust)
mean(room4$frust)
mean(room1$pairfollow)
mean(room4$pairfollow)
mean(room1$phistory)
mean(room4$phistory)
mean(room1$Skill_LoMdHi)
mean(room4$Skill_LoMdHi)
t.test(room1$frust, room4$frust)
cbind(room1$frust, room4$frust)
cbind(room1$frust, room4$frust)[,1]
mean(cbind(room1$frust, room4$frust)[,1])
aov(room1$frust, room4$frust)
?aobv
?aov
rbind(room1$frust, room4$frust)
c(room1$frust, room4$frust)
rbind(c(rep(1, 14), rep(2, 16)), c(room1$frust, room4$frust))
testi <- rbind(c(rep(1, 14), rep(2, 16)), c(room1$frust, room4$frust))
testi <- t(rbind(c(rep(1, 14), rep(2, 16)), c(room1$frust, room4$frust)))
colnames(testi) <- c("room", "frustration")
testi
aov(frustration ~ room, testi)
testi <- as.data.frame(testi)
aov(frustration ~ room, testi)
aov(room ~ frustration, testi)
summary(aov(room ~ frustration, testi))
t.test(room1$frust, room4$frust)
median(room1$frust)
median(room4$frust)
df$CollTht1
median(room1$sleepy)
median(room4$sleepy)
mean(room1$sleepy)
mean(room4$sleepy)
mydata
df
df$CollAvg
room1$CollAvg
room4$CollAvg
mean(room1$CollAvg)
mean(omit.na(room1$CollAvg))
mean(na.omit(room1$CollAvg))
mean(na.omit(room4$CollAvg))
mean(na.omit(room1$DiffAvg))
mean(na.omit(room4$DiffAvg))
boxplot(testi$frustration)
boxplot(testi$frustration ~ testi$room)
save.image("~/Benslab/PairCodingR4P/bco_playground/similarity.RData")
exit()
q()
x <- c(1, 2, 3)
y <- x + 1
z <- y *
2
y <- x + 2
z <- y * 2
y <- x + 3
z <- y * 2
?l2
testi <- norm(x)
?norm
x <- as.matrix(c(1, 2, 3))
y <- x + 3
z <- y * 2
norm(x)
norm(x, 2)
norm(x, 2)
norm(x, '2')
mean(x)
sqrt(x[1]^2 + x[2]^2 + x[3]^2)
norm(y, '2')
norm(z, '2')
?sqrt
source('~/Dropbox/PROJECT_CENT/Publications/WIP - Learning Curves/R/./znbnUtils.R')
gm_mean(x)
gm_mean(y)
gm_mean(z)
x[1] = 100
gm_mean(x)
mean(x)
mean(c(x,y,z))
gm_mean(c(x,y,z))
gmall <- gm_mean(c(x,y,z))
mxall <- max(c(x,y,z))
gmall <- c(gm_mean(x), gm_mean(y), gm_mean(z))
gmall <- gm_mean(c(x,y,z))
gmssn <- c(gm_mean(x), gm_mean(y), gm_mean(z))
mxssn <- max(gmssn)
R --version
version
which R
version
q()
q()
version
q()
version
install.packages("rtdists")
ap <- available.packages()
?setRepositories
chooseCRANmirror()
ap <- available.packages()
install.packages("rtdists")
install.packages("gsl")
install.packages("gsl")
install.packages("gsl")
install.packages("rtdists")
version
q()
x = seq(1, 5)
x = seq(1, 6)
y = 10 ^x
plot(y)
ggplot2::aes(x, y)
ggplot2(aes(x, y))
ggplot(aes(x, y))
library(ggplot2)
ggplot(aes(x, y))
ggplot(y, aes(x=x, y=y))
?line
line(x,y)
library(dplyr)
setwd('~/Dropbox/CV_MyJob_Professional_stuff/CurriculumVitae/CitationManagement')
# SCRAPE MY GOOGLE SCHOLAR PAGE
source("scrape_scholar.R")
my_id = "0Nzig9AAAAAJ" # Google Scholar ID for Ben Cowley
schlr_pubs = get_publications(my_id)
# summary(schlr_pubs$cites)
write.csv(select(schlr_pubs, title, year, cites), file = "gen/scholar_cites.csv")# WRITE TO CSV
# READ SCOPUS FROM DOWNLOADED CSV
# sco_pubs <- read.csv('scopus_manual.csv')
source("scopusAPI-master/scopusAPI.R") # Contains my Elsevier API key "61b72f5e1b8cc52cf30cf5f68d87cbe9"
theXML <- searchByID(theIDs = "scopusEID.txt", idtype = "eid", outfile = 'gen/scopus.csv')
sco_pubs <- extractXML(theXML)
# UPDATE CITATION COUNTS IN ORIGINAL DATA AND WRITE TO HANDY FILES
A1 <- read.delim('orig/A1orig.csv', quote = "")
A1 <- updateScholar(A1, schlr_pubs)
A1 <- updateScopus(A1, sco_pubs)
write.table(A1, file = "gen/A1.csv", sep = "\t", quote = FALSE, na = "-", row.names = FALSE, col.names = FALSE)
A2 <- read.delim('orig/A2orig.csv', quote = "")
A2 <- updateScholar(A2, schlr_pubs)
A2 <- updateScopus(A2, sco_pubs)
write.table(A2, file = "gen/A2.csv", sep = "\t", quote = FALSE, na = "-", row.names = FALSE, col.names = FALSE)
A3 <- read.delim('orig/A3orig.csv', quote = "")
A3 <- updateScholar(A3, schlr_pubs)
A3 <- updateScopus(A3, sco_pubs)
write.table(A3, file = "gen/A3.csv", sep = "\t", quote = FALSE, na = "-", row.names = FALSE, col.names = FALSE)
A4 <- read.delim('orig/A4orig.csv', quote = "")
A4 <- updateScholar(A4, schlr_pubs)
A4 <- updateScopus(A4, sco_pubs)
write.table(A4, file = "gen/A4.csv", sep = "\t", quote = FALSE, na = "-", row.names = FALSE, col.names = FALSE)
B1 <- read.delim('orig/B1orig.csv', quote = "")
G3 <- read.delim('orig/G3orig.csv', quote = "")
# COMBINE ALL CITATION-COUNT TABLES TO MAKE PUBLICATIONS TEX FILE
library(readr)
sec1 <- read_file("orig/sec-pub1.txt")
txA1 <- read_file("gen/A1.csv")
sec2 <- read_file("orig/sec-pub2.txt")
txA2 <- read_file("gen/A2.csv")
sec3 <- read_file("orig/sec-pub3.txt")
txA3 <- read_file("gen/A3.csv")
sec4 <- read_file("orig/sec-pub4.txt")
txA4 <- read_file("gen/A4.csv")
sec5 <- read_file("orig/sec-pub5.txt")
write_file(paste0(sec1, txA1, sec2, txA2, sec3, txA3, sec4, txA4, sec5), "../Latex/sec-publications.tex")
